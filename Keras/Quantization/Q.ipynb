{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KimMZUVqcJ8_"
   },
   "source": [
    "##### Copyright 2021 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BlWzg1D9_EhW"
   },
   "source": [
    "# Inspecting Quantization Errors with Quantization Debugger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XLoHL19yb-a0"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/lite/performance/quantization_debugger\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/performance/quantization_debugger.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/performance/quantization_debugger.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/tensorflow/tensorflow/lite/g3doc/performance/quantization_debugger.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://tfhub.dev/google/imagenet/mobilenet_v3_small_100_224/classification/5\"><img src=\"https://www.tensorflow.org/images/hub_logo_32px.png\" />See TF Hub model</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qTEEzJWo_iZ_"
   },
   "source": [
    "### Setup\n",
    "\n",
    "This section prepares libraries, MobileNet v3 model, and test dataset of 100\n",
    "images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "l7epUDUP_6qo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/ehsan/Partial_Q/Keras/env_Q_partial/lib/python3.10/site-packages (2.1.2)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /home/ehsan/Partial_Q/Keras/env_Q_partial/lib/python3.10/site-packages (from pandas) (1.26.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ehsan/Partial_Q/Keras/env_Q_partial/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ehsan/Partial_Q/Keras/env_Q_partial/lib/python3.10/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/ehsan/Partial_Q/Keras/env_Q_partial/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/ehsan/Partial_Q/Keras/env_Q_partial/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in /home/ehsan/Partial_Q/Keras/env_Q_partial/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ehsan/Partial_Q/Keras/env_Q_partial/lib/python3.10/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ehsan/Partial_Q/Keras/env_Q_partial/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ehsan/Partial_Q/Keras/env_Q_partial/lib/python3.10/site-packages (from matplotlib) (4.44.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/ehsan/Partial_Q/Keras/env_Q_partial/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /home/ehsan/Partial_Q/Keras/env_Q_partial/lib/python3.10/site-packages (from matplotlib) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ehsan/Partial_Q/Keras/env_Q_partial/lib/python3.10/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/ehsan/Partial_Q/Keras/env_Q_partial/lib/python3.10/site-packages (from matplotlib) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/ehsan/Partial_Q/Keras/env_Q_partial/lib/python3.10/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ehsan/Partial_Q/Keras/env_Q_partial/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ehsan/Partial_Q/Keras/env_Q_partial/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "#!jupyter nbconvert --to script Q.ipynb\n",
    "###!jupytext --set-formats ipynb,py Q.py --sync\n",
    "# Quantization debugger is available from TensorFlow 2.7.0\n",
    "#!pip uninstall -y tensorflow\n",
    "#!pip install tf-nightly\n",
    "#!pip install tensorflow_datasets --upgrade  # imagenet_v2 needs latest checksum\n",
    "#!pip install tensorflow_hub\n",
    "\n",
    "!pip install pandas\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "LLsgiUZe_hIa",
    "lines_to_next_cell": 2,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-09 04:18:55.366650: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-09 04:18:55.406146: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-09 04:18:55.406201: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-09 04:18:55.406227: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-09 04:18:55.412908: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-09 04:18:55.414141: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-09 04:18:56.310292: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ehsan/Partial_Q/Keras/env_Q_partial/bin/python\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "#import tensorflow_datasets as tfds\n",
    "#import tensorflow_hub as hub\n",
    "\n",
    "from tensorflow.lite.python import convert\n",
    "import pickle\n",
    "import os\n",
    "from tensorflow.lite.python import interpreter as interpreter_wrapper\n",
    "import numpy as np\n",
    "import time\n",
    "import threading\n",
    "import pandas as pd \n",
    "import sys\n",
    "import os\n",
    "import itertools\n",
    "cur_dir=os.getcwd()\n",
    "sys.path.append(cur_dir+'/../')\n",
    "import accuracy_multithread as tt\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df=pd.read_csv(\"df.csv\",index_col=0)\\ndf = pd.DataFrame(columns=[\"name\",\"mAP\"])\\ndf.loc[0]=[\"a\", 3.2]\\ndf.loc[1]=[\"b\", 4.1]\\ndf.to_csv(\"test.csv\")\\ndf2=pd.read_csv(\"test.csv\",index_col=0)\\ndf2.loc[2]=[\"c\", 5.1]\\ndf2\\ndf.loc[71]=[\"2\",3]'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''df=pd.read_csv(\"df.csv\",index_col=0)\n",
    "df = pd.DataFrame(columns=[\"name\",\"mAP\"])\n",
    "df.loc[0]=[\"a\", 3.2]\n",
    "df.loc[1]=[\"b\", 4.1]\n",
    "df.to_csv(\"test.csv\")\n",
    "df2=pd.read_csv(\"test.csv\",index_col=0)\n",
    "df2.loc[2]=[\"c\", 5.1]\n",
    "df2\n",
    "df.loc[71]=[\"2\",3]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "server=1\n",
    "GPU=1\n",
    "\n",
    "Proj_DIR=\"\"\n",
    "if server:\n",
    "    Proj_DIR=\"/home/ehsan/Partial_Q/\"\n",
    "    \n",
    "    \n",
    "# Constants\n",
    "model_name='MobileNet.h5'\n",
    "mm=model_name.split('.')[0]\n",
    "models_dir=Proj_DIR+'/models/MobileNet/'\n",
    "\n",
    "IMAGE_DIR = Proj_DIR+'/Imagenet/ILSVRC2012_img_val'\n",
    "LABEL_FILE = Proj_DIR+'/Evaluation/Ground_labels/ground_labels.txt'\n",
    "BATCH_SIZE = 1000  # Adjust as needed\n",
    "N=50000\n",
    "NUM_CLASSES = 1000  # Number of ImageNet classes\n",
    "    \n",
    "#data_dir = p+\"YOLOV3/Dataset/val2017\"\n",
    "image_size = (224, 224)\n",
    "N=1000\n",
    "\n",
    "RESULT_DIR=Proj_DIR+'/Keras/Quantization/Res/'\n",
    "\n",
    "\n",
    "resdir='Yolo_files/'\n",
    "ModelName=models_dir+model_name\n",
    "QuantizedName=RESULT_DIR+mm+'_quztized.tflite'\n",
    "QSelectiveName=RESULT_DIR+mm+'_selective_quztized.tflite'\n",
    "UQSelectiveName=RESULT_DIR+mm+'_selective_unquztized.tflite'\n",
    "RESULTS_FILE = RESULT_DIR+mm+'_debugger_results.csv'\n",
    "RESULTS_FILE_ANALYZED = RESULT_DIR+mm+'_debugger_results_analyzed.csv'\n",
    "RESULTS_FILE_Propogate = RESULT_DIR+mm+'_debugger_propogate_results.csv'\n",
    "RESULTS_FILE_Propogate_ANALYZED = RESULT_DIR+mm+'_debugger_propogate_results_analyzed.csv'\n",
    "DebuggerName=RESULT_DIR+'Debugger_'+mm+'.pkl'\n",
    "DebuggerPropogateName=RESULT_DIR+'Debugger_'+mm+'_propogation.pkl'\n",
    "CalibratedName=RESULT_DIR+mm+'_calibrated.tflite'\n",
    "\n",
    "\n",
    "# Define the input shape and data type\n",
    "input_shape = (1, 224, 224, 3)\n",
    "input_dtype = tf.float32\n",
    "\n",
    "# Define the output shape and data type\n",
    "output_shape = (1,)\n",
    "output_dtype = tf.float32\n",
    "\n",
    "if GPU:\n",
    "    #tf.debugging.set_log_device_placement(True)\n",
    "    physical_devices = tf.config.list_physical_devices('GPU')\n",
    "    print(physical_devices)\n",
    "    #tf.config.experimental.set_memory_growth(physical_devices[0], True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "lines_to_end_of_cell_marker": 2,
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def load_model(m=ModelName):\n",
    "    model = tf.keras.models.load_model(m)\n",
    "    return model\n",
    "\n",
    "#Partial\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
    "# Preprocessing function\n",
    "'''def preprocess_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    return x'''\n",
    "\n",
    "def preprocess_image(img_path):\n",
    "    # Read the image file into a tensor\n",
    "    img_raw = tf.io.read_file(img_path)\n",
    "    # Decode the image file into a tensor\n",
    "    img_tensor = tf.image.decode_jpeg(img_raw, channels=3)\n",
    "    # Resize the image tensor\n",
    "    img_final = tf.image.resize(img_tensor, image_size)\n",
    "    # Preprocess the image tensor for MobileNet\n",
    "    x = preprocess_input(img_final)\n",
    "    return x\n",
    "\n",
    "#Q:\n",
    "# Define a function to load and preprocess each image\n",
    "def Q_preprocess_image(file_path):\n",
    "    # Load the image\n",
    "    image = tf.io.read_file(file_path)\n",
    "    # Decode the JPEG image to a tensor\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    # Resize the image to the desired size\n",
    "    image = tf.image.resize(image, image_size)\n",
    "    # Normalize the pixel values to the range [0, 1]\n",
    "    image = image / 255.0\n",
    "    return image\n",
    "\n",
    "#train_dataset = tf.data.Dataset.from_tensor_slices((images))\n",
    "#train_dataset=train_dataset.map(process_image)\n",
    "def load_dataset():\n",
    "    # Create a list of file paths to the JPEG images\n",
    "    print(IMAGE_DIR)\n",
    "    file_paths = tf.data.Dataset.list_files(IMAGE_DIR + \"/*.JPEG\")\n",
    "    print(len(file_paths))\n",
    "    # Use the map() method to apply the preprocessing function to each image\n",
    "    dataset = file_paths.map(preprocess_image)\n",
    "    #dataset = dataset.map(lambda x: {'input_1': x})\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ehsan/Partial_Q//Imagenet/ILSVRC2012_img_val\n",
      "50000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<_MapDataset element_spec=TensorSpec(shape=(224, 224, 3), dtype=tf.float32, name=None)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "lines_to_end_of_cell_marker": 2,
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef amend_input(m=CalibratedName):\\n    interpreter = tf.lite.Interpreter(model_path=m)\\n    interpreter.allocate_tensors()\\n\\n    input_details = interpreter.get_input_details()\\n    input_shape = input_details[0]['shape']\\n    input_shape[1] = 608\\n    input_shape[2] = 608\\n    interpreter.resize_tensor_input(0, input_shape)\\n    interpreter.allocate_tensors()\\n    print(interpreter.get_input_details())\\n    converter = tf.lite.TFLiteConverter.from_interpreter(interpreter)\\n    #converter.allow_custom_ops = True  # If you have any custom ops in your model\\n    tflite_model = converter.convert()\\n    with open('modified_model.tflite', 'wb') as f:\\n        f.write(tflite_model)\\n\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def gen_rep():\n",
    "    train_dataset=prepare_dataset()    \n",
    "    representative_dataset = train_dataset.take(100).batch(1)\n",
    "    return representative_dataset\n",
    "    \n",
    "def representative_dataset(dataset):\n",
    "\tdef _data_gen():\n",
    "\t\tfor data in dataset.batch(1):\n",
    "\t\t\tyield [data['image']]\n",
    "\treturn _data_gen\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "#representative_dataset = dataset.take(300).batch(1)\n",
    "def rep(_dataset,n=N):\n",
    "    def representative_dataset():\n",
    "        for img in _dataset.take(n):\n",
    "            #img = tf.cast(img, tf.float32)\n",
    "            yield {'input_1': np.array([img])}\n",
    "            #yield np.array(img)\n",
    "    #return tf.data.Dataset.from_generator(representative_dataset, {'input_1': tf.float32}, {'input_1': tf.TensorShape([1, None, None, 3])})\n",
    "    return representative_dataset\n",
    "\n",
    "def rep2(_dataset,n=N):\n",
    "    def representative_dataset():\n",
    "        for img in _dataset.take(n):\n",
    "            #img = tf.cast(img, tf.float32)\n",
    "            \n",
    "            #img = tf.expand_dims(img, axis=0)\n",
    "            #yield [np.array(img)]\n",
    "            \n",
    "            yield [np.array([img])]\n",
    "    return representative_dataset\n",
    "\n",
    "def rep3(_dataset,n=N):\n",
    "    for img in _dataset.take(n):\n",
    "        yield [np.array([img])]\n",
    "\n",
    "def quantize(model,_dataset,name=QuantizedName):\n",
    "    print(\"\\n\\n\\n\\n***************************************************\")\n",
    "    print(\"quantization...\\n\")\n",
    "    if False and (os.path.isfile(QuantizedName)):\n",
    "        print(f\"loading existed {QuantizedName}\")\n",
    "        with open(name, 'rb') as f:\n",
    "            quantized_model=f.read()\n",
    "    else:\n",
    "        print(f'quantization: producing file {QuantizedName}')\n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "        converter.representative_dataset = tf.lite.RepresentativeDataset(rep(_dataset))\n",
    "        converter.representative_dataset = rep2(_dataset,N)\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        #converter.target_spec.supported_ops = [\n",
    "        #    tf.lite.OpsSet.TFLITE_BUILTINS_INT8_GPU \n",
    "        #]\n",
    "        #converter.inference_input_type = tf.uint8\n",
    "        #converter.inference_output_type = tf.uint8\n",
    "        converter.experimental_enable_resource_variables = True\n",
    "        converter.target_spec.supported_types = [tf.int8]\n",
    "\n",
    "        quantized_model = converter.convert()\n",
    "        open(name, \"wb\").write(quantized_model)\n",
    "    return quantized_model\n",
    "\n",
    "def explore(model,_dataset,debugger_name=DebuggerName):\n",
    "    print(\"\\n\\n\\n\\n***************************************************\")\n",
    "    print(\"explore...\\n\")\n",
    "    if (os.path.isfile(DebuggerName)):\n",
    "        print(f'loading existed file {DebuggerName}')\n",
    "        with open(debugger_name, 'rb') as f:\n",
    "            debugger=pickle.load(f)\n",
    "    elif (os.path.isfile(RESULTS_FILE)):\n",
    "        print(f'explore not required, existed file {RESULTS_FILE}')\n",
    "        return \n",
    "    else:\n",
    "        print(f'explore: producing file {DebuggerName}...')\n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        #converter.representative_dataset = rep2(_dataset,N)\n",
    "        converter.representative_dataset = tf.lite.RepresentativeDataset(rep2(_dataset))\n",
    "        # my_debug_dataset should have the same format as my_representative_dataset\n",
    "        #debug_dataset=tf.lite.RepresentativeDataset(rep3(_dataset))\n",
    "        debugger = tf.lite.experimental.QuantizationDebugger(\n",
    "            converter=converter, debug_dataset=rep2(_dataset))\n",
    "        #with open(debugger_name, 'wb') as f:\n",
    "        #    pickle.dump(debugger, f)\n",
    "\n",
    "    return debugger\n",
    "\n",
    "def run_debugger(debugger,res_file):\n",
    "    print(\"\\n\\n\\n\\n***************************************************\")\n",
    "    print(\"run debugger...\\n\")\n",
    "    if not (os.path.isfile(res_file)):\n",
    "        print(f'run_debugger: producing file {res_file}')\n",
    "        debugger.run()\n",
    "        with open(res_file, 'w') as f:\n",
    "            debugger.layer_statistics_dump(f)\n",
    "    else:\n",
    "        print(f'run_debugger: file is existed; {res_file}')\n",
    "\n",
    "def Analyze(res_file=RESULTS_FILE_ANALYZED,t=-.33):\n",
    "    print(\"\\n\\n\\n\\n***************************************************\")\n",
    "    print(\"Analyze...\\n\")\n",
    "    layer_stats = pd.read_csv(res_file)\n",
    "    layer_stats.head()\n",
    "    layer_stats['range'] = 255.0 * layer_stats['scale']\n",
    "    layer_stats['rmse/scale'] = layer_stats.apply(\n",
    "        lambda row: np.sqrt(row['mean_squared_error']) / row['scale'], axis=1)\n",
    "    layer_stats[['op_name', 'range', 'rmse/scale']].head()\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    ax1 = plt.subplot(121)\n",
    "    ax1.bar(np.arange(len(layer_stats)), layer_stats['range'])\n",
    "    ax1.set_ylabel('range')\n",
    "    ax2 = plt.subplot(122)\n",
    "    ax2.bar(np.arange(len(layer_stats)), layer_stats['rmse/scale'])\n",
    "    ax2.set_ylabel('rmse/scale')\n",
    "    plt.show()\n",
    "    #print(layer_stats[layer_stats['rmse/scale'] > t][['op_name', 'range', 'rmse/scale', 'tensor_name']])\n",
    "    layer_stats.to_csv(res_file,sep=',')\n",
    "\n",
    "def selective_quantize(model,_dataset,t=0.33, p=0.5):\n",
    "    print(\"\\n\\n\\n\\n***************************************************\")\n",
    "    print(\"selective quantization...\\n\")\n",
    "    caching=False\n",
    "    if (os.path.isfile(QSelectiveName)) and caching:\n",
    "        print(f'selective quantization: loading existed file {QSelectiveName}')\n",
    "        with open(QSelectiveName, \"rb\") as f:\n",
    "            selective_quantized_model=f.read()\n",
    "    else:\n",
    "        print(f'selective_quatize: producing file {QSelectiveName}')\n",
    "        layer_stats = pd.read_csv(RESULTS_FILE)\n",
    "        suspected_layers = list(layer_stats[layer_stats['rmse/scale'] > t]['tensor_name'])\n",
    "        nn=len(list(layer_stats['tensor_name']))\n",
    "        print(f'Number of layers:{nn}, suspected:{len(suspected_layers)}, unquantized first {int(p*nn)} layers')\n",
    "        suspected_layers.extend(list(layer_stats[:int(p*nn)]['tensor_name']))\n",
    "        print(len(suspected_layers))\n",
    "        print(len(list(set(suspected_layers))))\n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        converter.representative_dataset = rep(_dataset,N)\n",
    "        debug_options = tf.lite.experimental.QuantizationDebugOptions(denylisted_nodes=suspected_layers)\n",
    "        debugger = tf.lite.experimental.QuantizationDebugger(\n",
    "            converter=converter,debug_dataset=rep(_dataset,N),debug_options=debug_options)\n",
    "        selective_quantized_model = debugger.get_nondebug_quantized_model()\n",
    "        open(QSelectiveName, \"wb\").write(selective_quantized_model)\n",
    "    return selective_quantized_model\n",
    "\n",
    "def calibrate(model,_dataset,name=CalibratedName):\n",
    "    print(\"\\n\\n\\n\\n***************************************************\")\n",
    "    print(\"calibrate...\\n\")\n",
    "    if (os.path.isfile(CalibratedName)):\n",
    "        print(f'calibrate: loading existing file {CalibratedName}')\n",
    "        with open(name, 'rb') as f:\n",
    "            calibrated_model = f.read()\n",
    "    else:\n",
    "        print(f\"calibrate producing file {CalibratedName}\")\n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "        converter.representative_dataset = rep2(_dataset)\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        converter._experimental_calibrate_only = True\n",
    "        converter.inference_input_type = input_dtype\n",
    "        converter.inference_output_type = output_dtype\n",
    "        converter.inference_input_shape = input_shape\n",
    "        converter.inference_output_shape = output_shape\n",
    "        calibrated_model = converter.convert()\n",
    "        open(name, \"wb\").write(calibrated_model)\n",
    "    return calibrated_model\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def explore_propogation(calibrated_model,_dataset,debugger_name=DebuggerPropogateName):\n",
    "    print(\"\\n\\n\\n\\n***************************************************\")\n",
    "    print(\"explore propogation...\\n\")\n",
    "    if (os.path.isfile(DebuggerPropogateName)):\n",
    "        print(f'explore propogation: loading existed file {DebuggerPropogateName}')\n",
    "        with open(debugger_name, 'rb') as f:\n",
    "            debugger=pickle.load(f)\n",
    "    elif (os.path.isfile(RESULTS_FILE_Propogate)):\n",
    "        print(f'explore propogate not required, existed file {RESULTS_FILE_Propogate}')\n",
    "        return\n",
    "    else:\n",
    "        print(f\"explore_propogation: Producing file {DebuggerPropogateName}\")\n",
    "        # Note that enable_numeric_verify and enable_whole_model_verify are set.\n",
    "        quantized_model = convert.mlir_quantize(\n",
    "            calibrated_model,\n",
    "            enable_numeric_verify=True,\n",
    "            enable_whole_model_verify=True)\n",
    "        debugger = tf.lite.experimental.QuantizationDebugger(\n",
    "            quant_debug_model_content=quantized_model,\n",
    "            debug_dataset=rep2(_dataset))\n",
    "        #with open(debugger_name, 'wb') as f:\n",
    "        #    pickle.dump(debugger, f)\n",
    "    return debugger\n",
    "\n",
    "def explore_combinations(calibrated_model,suspected_layers=[],t=0.35,name=UQSelectiveName):\n",
    "    print(\"\\n\\n\\n\\n***************************************************\")\n",
    "    print(\"explore combination...\\n\")\n",
    "    if (os.path.isfile(name)):\n",
    "        print(f'explore combinations: loading existed file {name}')\n",
    "        with open(name, 'rb') as f:\n",
    "            selective_quantized_model = f.read()\n",
    "    else:\n",
    "        print(f\"explore_combinations: producing file {name}\")\n",
    "        layer_stats = pd.read_csv(RESULTS_FILE)\n",
    "        suspected_layers.extend(list(layer_stats[layer_stats['rmse/scale'] > t]['tensor_name']))\n",
    "        suspected_layers.extend(list(layer_stats[:10]['tensor_name']))\n",
    "        selective_quantized_model = convert.mlir_quantize(calibrated_model, denylisted_nodes=suspected_layers)\n",
    "        open(name, \"wb\").write(selective_quantized_model)\n",
    "    return selective_quantized_model\n",
    "\n",
    "def explore_combinations2(calibrated_model,suspected_layers=[],name=UQSelectiveName):\n",
    "    print(\"\\n\\n\\n\\n***************************************************\")\n",
    "    print(\"explore combination...\\n\")\n",
    "    caching=False\n",
    "    if (os.path.isfile(name)) and caching:\n",
    "        print(f'explore combinations: loading existed file {name}')\n",
    "        with open(name, 'rb') as f:\n",
    "            selective_quantized_model = f.read()\n",
    "    else:\n",
    "        print(f\"explore_combinations: producing file {name}\")\n",
    "        selective_quantized_model = convert.mlir_quantize(calibrated_model, denylisted_nodes=suspected_layers)\n",
    "        with open(name, \"wb\") as f:\n",
    "            f.write(selective_quantized_model)\n",
    "    return \n",
    "\n",
    "'''\n",
    "def amend_input(m=CalibratedName):\n",
    "    interpreter = tf.lite.Interpreter(model_path=m)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    input_details = interpreter.get_input_details()\n",
    "    input_shape = input_details[0]['shape']\n",
    "    input_shape[1] = 608\n",
    "    input_shape[2] = 608\n",
    "    interpreter.resize_tensor_input(0, input_shape)\n",
    "    interpreter.allocate_tensors()\n",
    "    print(interpreter.get_input_details())\n",
    "    converter = tf.lite.TFLiteConverter.from_interpreter(interpreter)\n",
    "    #converter.allow_custom_ops = True  # If you have any custom ops in your model\n",
    "    tflite_model = converter.convert()\n",
    "    with open('modified_model.tflite', 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize():\n",
    "    global model,dataset,calibrated_model\n",
    "    model=load_model(m=ModelName)\n",
    "    model.summary()\n",
    "    dataset=load_dataset()\n",
    "    # Print the first 5 images in the dataset\n",
    "    for image in dataset.take(5):\n",
    "        print(image.shape)\n",
    "    #global calibrated_model\n",
    "    calibrated_model=calibrate(model,dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#import imp\n",
    "#imp.reload(tt)\n",
    "def evaluate(model_name, pkl_name):\n",
    "    #cmd='cd ../Evaluation; python ../Evaluation/eval_multiThread2.py '+args\n",
    "    #os.system(cmd)\n",
    "    #mAP,APs=tt.main([\"--num_threads\",'64',\"--model_path\",model_name,\"--pkl_name\",pkl_name])\n",
    "    top1,top5=tt.main(model_name)\n",
    "    return top1,top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_indexes(start_conv=-1,end_conv=-1):\n",
    "    ####\n",
    "    layer_stats = pd.read_csv(RESULTS_FILE)\n",
    "    all_layers=list(layer_stats[:]['tensor_name'])\n",
    "    conv_layers=[]\n",
    "    for i,layer in enumerate(all_layers):\n",
    "        if 'conv' in layer or 'StatefulPartitionedCall' in layer:\n",
    "            conv_layers.append(layer)\n",
    "            \n",
    "    _n=len(conv_layers)\n",
    "    #cases=[ [ conv_layers[start:end+1] for end in range(start,_n) ] for start in range(0,_n) ]\n",
    "    #n_cases = [len(case) for case in cases ]\n",
    "    #N_cases = sum(n_cases)\n",
    "    cases=[  list(range(start,end+1))  for start in range(0,_n) for end in range(start,_n)]\n",
    "    N_cases = len(cases)\n",
    "    print(f'Total layers:{len(all_layers)}  Convs:{len(conv_layers)}  number of cases:{N_cases}')\n",
    "    #flatted_cases=[c for case in cases for c in case]\n",
    "    last_conv_indx=len(conv_layers)-1\n",
    "    for i,case in enumerate(cases):\n",
    "        start_conv=case[0]\n",
    "        end_conv=case[-1]\n",
    "        start_index=all_layers.index(conv_layers[start_conv])\n",
    "        if end_conv==last_conv_indx:\n",
    "            end_index=len(all_layers)-1\n",
    "        else:\n",
    "            end_index=all_layers.index(conv_layers[end_conv+1])\n",
    "        suspend=all_layers[0:start_index]+all_layers[end_index:]\n",
    "        #kk=list(set(all_layers)-set(suspend))\n",
    "        #print(f'quantizing conv layers from {start_conv} to {end_conv}')\n",
    "        #print(f'index {start_index} to {end_index}')\n",
    "        #print(all_layers[start_index:end_index])\n",
    "        #ttt=explore_combinations2(calibrated_model,suspected_layers=ss,name='2-3.tflite')'''\n",
    "        ##next_start_conv=cases[i+1]\n",
    "        ##next_end_conv=cases\n",
    "        yield i,N_cases,start_conv,end_conv,start_index,end_index,suspend\n",
    "\n",
    "        \n",
    "def run():\n",
    "    output=os.getcwd()+\"/cases/\"\n",
    "    os.makedirs(output, exist_ok=True)\n",
    "    i=0\n",
    "    pklDatafile=\"DataResults.pkl\"\n",
    "    dffile=\"df.csv\"\n",
    "    if os.path.isfile(dffile):\n",
    "        df=pd.read_csv(dffile,index_col=0)\n",
    "        #i=df.iloc[-1][0]+1\n",
    "        i=len(df)\n",
    "        print(f'Continue {dffile} from index {i}')\n",
    "    else:\n",
    "        response=input(\"Do you want to reset df.csv? yes/*   \")\n",
    "        if response==\"yes\" or response==\"Yes\":\n",
    "            df = pd.DataFrame(columns=[\"name\",\"mAP\"])\n",
    "        else:\n",
    "            return\n",
    "        \n",
    "    if os.path.isfile(pklDatafile):\n",
    "        with open(pklDatafile,'rb') as f:\n",
    "            Data=pickle.load(f)\n",
    "        print(f'{pklDatafile} is loaded')\n",
    "    else:\n",
    "        response=input(\"Do you want to reset DataResults.pkl? yes/*   \")\n",
    "        if response==\"yes\" or response==\"Yes\":\n",
    "            Data=[]\n",
    "        else:\n",
    "            return\n",
    "        \n",
    "    for c in generate_indexes():\n",
    "        '''if c[0]<i:\n",
    "            continue'''\n",
    "        #input(f'i is {i}')\n",
    "        print(\"\\n\\n\\n*****************\\n\\n\\n\")\n",
    "        print(f'Case:{c[0]}/{c[1]}')\n",
    "        print(f'quantizing conv layers from {c[2]} to {c[3]}')\n",
    "        print(f'index {c[4]} to {c[5]}')  \n",
    "        _name=f'{c[2]}-{c[3]}'\n",
    "        if df[df['name']==_name].shape[0]:\n",
    "            print(\"Already evaluated...\")\n",
    "            continue\n",
    "        \n",
    "        m_name=output+_name+'.tflite'\n",
    "        p_name=_name+'.pkl'\n",
    "        \n",
    "        start_time=time.time()\n",
    "        explore_combinations2(calibrated_model,suspected_layers=c[-1],name=m_name)\n",
    "        end_time=time.time()\n",
    "        print(f\"{m_name} Quantization finished time: {end_time-start_time}\")\n",
    "        \n",
    "        mAP,APs=evaluate(model_name=m_name,pkl_name=p_name)\n",
    "        end_time=time.time()\n",
    "        print(f\"{m_name} Evaluation finished time: {end_time-start_time}\")\n",
    "        \n",
    "        os.remove(m_name)\n",
    "        df.loc[c[0]]=[_name,mAP]\n",
    "        dct={\"i\":c[0],\"start_conv\":c[2], \"end_conv\":c[3], \"start_index\":c[4], \"end_index\":c[5],\"mAP\":mAP, \"APs\":APs}\n",
    "        Data.append(dct)\n",
    "        if c[0]%5==0 or True:\n",
    "            df.to_csv(dffile)\n",
    "            with open(pklDatafile,'wb') as f:\n",
    "                pickle.dump(Data,f)\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +\n",
    "def generate_indexes_2(start_conv=-1,end_conv=-1):\n",
    "    ####\n",
    "    layer_stats = pd.read_csv(RESULTS_FILE)\n",
    "    all_layers=list(layer_stats[:]['tensor_name'])\n",
    "    conv_layers=[]\n",
    "    #print(all_layers)\n",
    "    for i,layer in enumerate(all_layers):\n",
    "        if 'conv' in layer or 'StatefulPartitionedCall' in layer:\n",
    "            conv_layers.append(layer)\n",
    "            \n",
    "    _n=len(conv_layers)\n",
    "    #cases=[ [ conv_layers[start:end+1] for end in range(start,_n) ] for start in range(0,_n) ]\n",
    "    #n_cases = [len(case) for case in cases ]\n",
    "    #N_cases = sum(n_cases)\n",
    "    #cases = list(itertools.combinations(conv_layers, 2))\n",
    "    _convs=list(range(len(conv_layers)))\n",
    "    cases=list(itertools.combinations(_convs, 1))\n",
    "    cases+=list(itertools.combinations(_convs, 2))\n",
    "    N_cases = len(cases)\n",
    "    print(f'Total layers:{len(all_layers)}  Convs:{len(conv_layers)}  number of cases:{N_cases}')\n",
    "    #flatted_cases=[c for case in cases for c in case]\n",
    "    last_conv_indx=len(conv_layers)-1\n",
    "    last_conv=conv_layers[-1]\n",
    "    for i,case in enumerate(cases):\n",
    "        print(f'case:\\n{case}')\n",
    "        suspend=all_layers[:]\n",
    "        quant=[]\n",
    "        for layer in case:           \n",
    "            start_index=all_layers.index(conv_layers[layer])\n",
    "            if layer==last_conv_indx:\n",
    "                end_index=len(all_layers)-1\n",
    "            else:\n",
    "                end_index=all_layers.index(conv_layers[layer+1])\n",
    "            block=[all_layers[j] for j in range(start_index,end_index)]\n",
    "            quant+=block\n",
    "        print(quant)         \n",
    "        suspend=[elem for elem in all_layers if elem not in quant]\n",
    "        print(len(quant),len(suspend),len(all_layers))\n",
    "        \n",
    "        \n",
    "        yield i,N_cases,tuple(case),suspend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "endofcell": "------"
   },
   "outputs": [],
   "source": [
    "# +\n",
    "def extract_one_two_from_consequtives():\n",
    "    m=pd.read_csv('df.csv',index_col=0)\n",
    "    m['layers'] = m['name'].str.split('-').apply(lambda x: tuple(range(int(x[0]), int(x[1])+1)))\n",
    "    #pd.set_option('display.max_rows',3000)\n",
    "    k=1\n",
    "    m_1=m[m['layers'].apply(len) == 1]\n",
    "    m_2=m[m['layers'].apply(len) == 2]\n",
    "    #m_filtered = m[m['layers'].apply(len).isin([1,2])]\n",
    "    ms=pd.concat([m_1,m_2],ignore_index=True)\n",
    "    ms.to_csv(\"extracted_df.csv\",index=False)\n",
    "    return ms\n",
    "#extract_one_two_from_consequtives()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t=extract_one_two_from_consequtives()\n",
    "#t[t['layers'].astype(str)=='(0,)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "endofcell": "-------",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def run_2():\n",
    "    output=os.getcwd()+\"/cases/\"\n",
    "    os.makedirs(output, exist_ok=True)\n",
    "    dffile=\"df2.csv\"\n",
    "    if os.path.isfile(dffile):\n",
    "        df=pd.read_csv(dffile,index_col=0)\n",
    "        #i=df.iloc[-1][0]+1\n",
    "        i=len(df)\n",
    "        print(f'Continue {dffile} from index {i}')\n",
    "    else:\n",
    "        response=input(\"Do you want to reset df.csv? yes/*   \")\n",
    "        if response==\"yes\" or response==\"Yes\":\n",
    "            df = pd.DataFrame(columns=[\"name\",\"mAP\"])\n",
    "        else:\n",
    "            return\n",
    "        \n",
    "    \n",
    "    extracted_df=extract_one_two_from_consequtives()\n",
    "    \n",
    "    for c in generate_indexes_2():\n",
    "        \n",
    "        print(\"\\n\\n\\n*****************\\n\\n\\n\")\n",
    "        print(f'Case:{c[0]}/{c[1]}')\n",
    "        print(f'quantizing conv layers {c[2]}')\n",
    "        _name=f'{c[2]}'\n",
    "        if df[df['name']==_name].shape[0]:\n",
    "            print(\"Already evaluated...\")\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        if extracted_df[extracted_df['layers'].astype(str)==_name].shape[0]:\n",
    "            mAP=extracted_df[extracted_df['layers'].astype(str)==_name]['mAP'].iloc[0]\n",
    "            df.loc[c[0]]=[_name,mAP]\n",
    "            df.to_csv(dffile)\n",
    "            print('extract')\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        m_name=output+_name+'.tflite'\n",
    "        p_name=_name+'.pkl'\n",
    "        \n",
    "        start_time=time.time()\n",
    "        explore_combinations2(calibrated_model,suspected_layers=c[-1],name=m_name)\n",
    "        end_time=time.time()\n",
    "        print(f\"{m_name} Quantization finished time: {end_time-start_time}\")\n",
    "        \n",
    "        mAP,APs=evaluate(model_name=m_name,pkl_name=p_name)\n",
    "        end_time=time.time()\n",
    "        print(f\"{m_name} Evaluation finished time: {end_time-start_time}\")\n",
    "        \n",
    "        os.remove(m_name)\n",
    "        df.loc[c[0]]=[_name,mAP]\n",
    "        \n",
    "        if c[0]%5==0 or True:\n",
    "            df.to_csv(dffile)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "endofcell": "--------",
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def generate_indexes_3(start_conv=-1,end_conv=-1):\n",
    "    ####\n",
    "    layer_stats = pd.read_csv(RESULTS_FILE)\n",
    "    all_layers=list(layer_stats[:]['tensor_name'])\n",
    "    conv_layers=[]\n",
    "    #print(all_layers)\n",
    "    for i,layer in enumerate(all_layers):\n",
    "        if 'conv' in layer or 'StatefulPartitionedCall' in layer:\n",
    "            conv_layers.append(layer)\n",
    "            \n",
    "    _n=len(conv_layers)\n",
    "    #cases=[ [ conv_layers[start:end+1] for end in range(start,_n) ] for start in range(0,_n) ]\n",
    "    #n_cases = [len(case) for case in cases ]\n",
    "    #N_cases = sum(n_cases)\n",
    "    #cases = list(itertools.combinations(conv_layers, 2))\n",
    "    _convs=list(range(len(conv_layers)))\n",
    "    #cases=list(itertools.combinations(_convs, 1))\n",
    "    #cases+=list(itertools.combinations(_convs, 2))\n",
    "    cases=list(itertools.combinations(_convs, 3))\n",
    "    N_cases = len(cases)\n",
    "    print(f'Total layers:{len(all_layers)}  Convs:{len(conv_layers)}  number of cases:{N_cases}')\n",
    "    #flatted_cases=[c for case in cases for c in case]\n",
    "    last_conv_indx=len(conv_layers)-1\n",
    "    last_conv=conv_layers[-1]\n",
    "    random.shuffle(cases)\n",
    "    for i,case in enumerate(cases):\n",
    "        print(f'case:\\n{case}')\n",
    "        suspend=all_layers[:]\n",
    "        quant=[]\n",
    "        for layer in case:           \n",
    "            start_index=all_layers.index(conv_layers[layer])\n",
    "            if layer==last_conv_indx:\n",
    "                end_index=len(all_layers)-1\n",
    "            else:\n",
    "                end_index=all_layers.index(conv_layers[layer+1])\n",
    "            block=[all_layers[j] for j in range(start_index,end_index)]\n",
    "            quant+=block\n",
    "        print(quant)         \n",
    "        suspend=[elem for elem in all_layers if elem not in quant]\n",
    "        print(len(quant),len(suspend),len(all_layers))\n",
    "        \n",
    "        \n",
    "        yield i,N_cases,tuple(case),suspend           \n",
    "            \n",
    "def run_3():\n",
    "    output=os.getcwd()+\"/cases/\"\n",
    "    os.makedirs(output, exist_ok=True)\n",
    "    dffile=\"df3.csv\"\n",
    "    if os.path.isfile(dffile):\n",
    "        df=pd.read_csv(dffile,index_col=0)\n",
    "        #i=df.iloc[-1][0]+1\n",
    "        i=len(df)\n",
    "        print(f'Continue {dffile} from index {i}')\n",
    "    else:\n",
    "        response=input(f\"Do you want to reset {dffile}? yes/*   \")\n",
    "        if response==\"yes\" or response==\"Yes\":\n",
    "            df = pd.DataFrame(columns=[\"name\",\"mAP\"])\n",
    "        else:\n",
    "            return\n",
    "        \n",
    "    \n",
    "    extracted_df=extract_one_two_from_consequtives()\n",
    "    \n",
    "    for c in generate_indexes_3():\n",
    "        \n",
    "        print(\"\\n\\n\\n*****************\\n\\n\\n\")\n",
    "        print(f'Case:{c[0]}/{c[1]}')\n",
    "        print(f'quantizing conv layers {c[2]}')\n",
    "        _name=f'{c[2]}'\n",
    "        if df[df['name']==_name].shape[0]:\n",
    "            print(\"Already evaluated...\")\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        if extracted_df[extracted_df['layers'].astype(str)==_name].shape[0]:\n",
    "            mAP=extracted_df[extracted_df['layers'].astype(str)==_name]['mAP'].iloc[0]\n",
    "            df.loc[c[0]]=[_name,mAP]\n",
    "            df.to_csv(dffile)\n",
    "            print('extract')\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        m_name=output+_name+'.tflite'\n",
    "        p_name=_name+'.pkl'\n",
    "        \n",
    "        start_time=time.time()\n",
    "        explore_combinations2(calibrated_model,suspected_layers=c[-1],name=m_name)\n",
    "        end_time=time.time()\n",
    "        print(f\"{m_name} Quantization finished time: {end_time-start_time}\")\n",
    "        \n",
    "        mAP,APs=evaluate(model_name=m_name,pkl_name=p_name)\n",
    "        end_time=time.time()\n",
    "        print(f\"{m_name} Evaluation finished time: {end_time-start_time}\")\n",
    "        \n",
    "        os.remove(m_name)\n",
    "        df.loc[c[0]]=[_name,mAP]\n",
    "        \n",
    "        if c[0]%5==0 or True:\n",
    "            df.to_csv(dffile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "endofcell": "--------",
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "            \n",
    "def generate_indexes_0():\n",
    "    ####\n",
    "    layer_stats = pd.read_csv(RESULTS_FILE)\n",
    "    all_layers=list(layer_stats[:]['tensor_name'])\n",
    "    conv_layers=[]\n",
    "    #print(all_layers)\n",
    "    for i,layer in enumerate(all_layers):\n",
    "        if 'conv' in layer or 'StatefulPartitionedCall' in layer:\n",
    "            conv_layers.append(layer)\n",
    "            \n",
    "    _n=len(conv_layers)\n",
    "    cases=list(np.zeros(_n))\n",
    "    cases+=list(np.ones(_n))\n",
    "    N_cases = len(cases)\n",
    "    print(f'Total layers:{len(all_layers)}  Convs:{len(conv_layers)}  number of cases:{N_cases}')\n",
    "    #flatted_cases=[c for case in cases for c in case]\n",
    "    last_conv_indx=len(conv_layers)-1\n",
    "    last_conv=conv_layers[-1]\n",
    "    random.shuffle(cases)\n",
    "    for i,case in enumerate(cases):\n",
    "        print(f'case:\\n{case}')\n",
    "        suspend=all_layers[:]\n",
    "        quant=[]\n",
    "        for layer in case:           \n",
    "            start_index=all_layers.index(conv_layers[layer])\n",
    "            if layer==last_conv_indx:\n",
    "                end_index=len(all_layers)-1\n",
    "            else:\n",
    "                end_index=all_layers.index(conv_layers[layer+1])\n",
    "            block=[all_layers[j] for j in range(start_index,end_index)]\n",
    "            quant+=block\n",
    "        print(quant)         \n",
    "        suspend=[elem for elem in all_layers if elem not in quant]\n",
    "        print(len(quant),len(suspend),len(all_layers))\n",
    "        \n",
    "        \n",
    "        yield i,N_cases,tuple(case),suspend      \n",
    "            \n",
    "            \n",
    "          \n",
    "\n",
    "        \n",
    "        \n",
    "def run_0():\n",
    "    output=os.getcwd()+\"/cases/\"\n",
    "    os.makedirs(output, exist_ok=True)\n",
    "    dffile=\"df0.csv\"\n",
    "    if os.path.isfile(dffile):\n",
    "        df=pd.read_csv(dffile,index_col=0)\n",
    "        #i=df.iloc[-1][0]+1\n",
    "        i=len(df)\n",
    "        print(f'Continue {dffile} from index {i}')\n",
    "    else:\n",
    "        response=input(f\"Do you want to reset {dffile}? yes/*   \")\n",
    "        if response==\"yes\" or response==\"Yes\":\n",
    "            df = pd.DataFrame(columns=[\"name\",\"mAP\"])\n",
    "        else:\n",
    "            return\n",
    "        \n",
    "    \n",
    "    \n",
    "    for c in generate_indexes_0():\n",
    "        \n",
    "        print(\"\\n\\n\\n*****************\\n\\n\\n\")\n",
    "        print(f'Case:{c[0]}/{c[1]}')\n",
    "        print(f'quantizing conv layers {c[2]}')\n",
    "        _name=f'{c[2]}'\n",
    "        if df[df['name']==_name].shape[0]:\n",
    "            print(\"Already evaluated...\")\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        if extracted_df[extracted_df['layers'].astype(str)==_name].shape[0]:\n",
    "            mAP=extracted_df[extracted_df['layers'].astype(str)==_name]['mAP'].iloc[0]\n",
    "            df.loc[c[0]]=[_name,mAP]\n",
    "            df.to_csv(dffile)\n",
    "            print('extract')\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        m_name=output+_name+'.tflite'\n",
    "        p_name=_name+'.pkl'\n",
    "        \n",
    "        start_time=time.time()\n",
    "        explore_combinations2(calibrated_model,suspected_layers=c[-1],name=m_name)\n",
    "        end_time=time.time()\n",
    "        print(f\"{m_name} Quantization finished time: {end_time-start_time}\")\n",
    "        \n",
    "        mAP,APs=evaluate(model_name=m_name,pkl_name=p_name)\n",
    "        end_time=time.time()\n",
    "        print(f\"{m_name} Evaluation finished time: {end_time-start_time}\")\n",
    "        \n",
    "        os.remove(m_name)\n",
    "        df.loc[c[0]]=[_name,mAP]\n",
    "        \n",
    "        if c[0]%5==0 or True:\n",
    "            df.to_csv(dffile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "endofcell": "--------",
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "def generate_indexes_MontCarlo(Num_points=4000):\n",
    "    layer_stats = pd.read_csv(RESULTS_FILE)\n",
    "    all_layers=list(layer_stats[:]['tensor_name'])\n",
    "    conv_layers=[]\n",
    "    #print(all_layers)\n",
    "    for i,layer in enumerate(all_layers):\n",
    "        if 'conv' in layer or 'StatefulPartitionedCall' in layer:\n",
    "            conv_layers.append(layer)\n",
    "            \n",
    "    _n=len(conv_layers)\n",
    "    _convs=list(range(len(conv_layers)))\n",
    "\n",
    "    '''\n",
    "    cases=list(np.zeros(_n))\n",
    "    cases+=list(np.ones(_n))\n",
    "    cases+=[  list(range(start,end+1))  for start in range(0,_n) for end in range(start,_n)]\n",
    "    cases+=list(itertools.combinations(_convs, 1))\n",
    "    cases+=list(itertools.combinations(_convs, 2))\n",
    "    cases+=list(itertools.combinations(_convs, 3))\n",
    "    '''\n",
    "\n",
    "    N_cases = Num_points\n",
    "    print(f'Total layers:{len(all_layers)}  Convs:{len(conv_layers)}  number of cases:{Num_points}')\n",
    "    #flatted_cases=[c for case in cases for c in case]\n",
    "    last_conv_indx=len(conv_layers)-1\n",
    "    last_conv=conv_layers[-1]\n",
    "    #random.shuffle(cases)\n",
    "    #for i,case in enumerate(cases):\n",
    "    sequences=[np.ones(75, dtype=int), np.zeros(75, dtype=int)]\n",
    "    for i in range(Num_points):\n",
    "        binary_sequence = np.random.randint(2, size=75)\n",
    "    #for i,binary_sequence in enumerate(sequences):\n",
    "        #\n",
    "        # Find the indices where the value is 1\n",
    "        indices_of_ones = np.where(binary_sequence == 1)[0]\n",
    "        indices_of_zeros = np.where(binary_sequence == 0)[0]\n",
    "        case=indices_of_ones\n",
    "        print(f'case:\\n{case}')\n",
    "        suspend=all_layers[:]\n",
    "        quant=[]\n",
    "        for layer in case:           \n",
    "            start_index=all_layers.index(conv_layers[layer])\n",
    "            if layer==last_conv_indx:\n",
    "                end_index=len(all_layers)-1\n",
    "            else:\n",
    "                end_index=all_layers.index(conv_layers[layer+1])\n",
    "            block=[all_layers[j] for j in range(start_index,end_index)]\n",
    "            quant+=block\n",
    "        print(quant)         \n",
    "        suspend=[elem for elem in all_layers if elem not in quant]\n",
    "        print(len(quant),len(suspend),len(all_layers))\n",
    "        \n",
    "        \n",
    "        yield i,N_cases,tuple(case),suspend  \n",
    "\n",
    "\n",
    "def run_MontCarlo(_Num_points=4000):\n",
    "    output=os.getcwd()+\"/cases/\"\n",
    "    os.makedirs(output, exist_ok=True)\n",
    "    dffile=\"df_MontCarlo.csv\"\n",
    "    if os.path.isfile(dffile):\n",
    "        df=pd.read_csv(dffile,index_col=0)\n",
    "        #i=df.iloc[-1][0]+1\n",
    "        i=len(df)\n",
    "        print(f'Continue {dffile} from index {i}')\n",
    "    else:\n",
    "        response=input(f\"Do you want to reset {dffile}? yes/*   \")\n",
    "        if response==\"yes\" or response==\"Yes\":\n",
    "            df = pd.DataFrame(columns=[\"name\",\"mAP\"])\n",
    "        else:\n",
    "            return\n",
    "        \n",
    "    cntr=0\n",
    "    \n",
    "    for c in generate_indexes_MontCarlo(Num_points=_Num_points):\n",
    "        \n",
    "        print(\"\\n\\n\\n*****************\\n\\n\\n\")\n",
    "        print(f'Case:{c[0]}/{c[1]}')\n",
    "        print(f'quantizing conv layers {c[2]}')\n",
    "        _name=f'{c[2]}'\n",
    "        \n",
    "        if df[df['name']==_name].shape[0]:\n",
    "            print(\"Already evaluated...\")\n",
    "            continue\n",
    "            \n",
    "        _name=_name.replace(' ','')\n",
    "        \n",
    "        if df[df['name']==_name].shape[0]:\n",
    "            print(\"Already evaluated...\")\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        m_name=output+_name+'.tflite'\n",
    "        p_name=_name+'.pkl'\n",
    "        \n",
    "        start_time=time.time()\n",
    "        explore_combinations2(calibrated_model,suspected_layers=c[-1],name=m_name)\n",
    "        end_time=time.time()\n",
    "        print(f\"{m_name} Quantization finished time: {end_time-start_time}\")\n",
    "        \n",
    "        mAP,APs=evaluate(model_name=m_name,pkl_name=p_name)\n",
    "        end_time=time.time()\n",
    "        print(f\"{m_name} Evaluation finished time: {end_time-start_time}\")\n",
    "        \n",
    "        os.remove(m_name)\n",
    "        #df.loc[c[0]]=[_name,mAP]\n",
    "        df.loc[len(df)]=[_name,mAP]\n",
    "        \n",
    "        if c[0]%5==0 or True:\n",
    "            df.to_csv(dffile)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "endofcell": "--------",
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"mobilenet_1.00_224\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv1_pad (ZeroPadding2D)   (None, 225, 225, 3)       0         \n",
      "                                                                 \n",
      " conv1 (Conv2D)              (None, 112, 112, 32)      864       \n",
      "                                                                 \n",
      " conv1_bn (BatchNormalizati  (None, 112, 112, 32)      128       \n",
      " on)                                                             \n",
      "                                                                 \n",
      " conv1_relu (ReLU)           (None, 112, 112, 32)      0         \n",
      "                                                                 \n",
      " conv_dw_1 (DepthwiseConv2D  (None, 112, 112, 32)      288       \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_1_bn (BatchNormali  (None, 112, 112, 32)      128       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_1_relu (ReLU)       (None, 112, 112, 32)      0         \n",
      "                                                                 \n",
      " conv_pw_1 (Conv2D)          (None, 112, 112, 64)      2048      \n",
      "                                                                 \n",
      " conv_pw_1_bn (BatchNormali  (None, 112, 112, 64)      256       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_1_relu (ReLU)       (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " conv_pad_2 (ZeroPadding2D)  (None, 113, 113, 64)      0         \n",
      "                                                                 \n",
      " conv_dw_2 (DepthwiseConv2D  (None, 56, 56, 64)        576       \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_2_bn (BatchNormali  (None, 56, 56, 64)        256       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_2_relu (ReLU)       (None, 56, 56, 64)        0         \n",
      "                                                                 \n",
      " conv_pw_2 (Conv2D)          (None, 56, 56, 128)       8192      \n",
      "                                                                 \n",
      " conv_pw_2_bn (BatchNormali  (None, 56, 56, 128)       512       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_2_relu (ReLU)       (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv_dw_3 (DepthwiseConv2D  (None, 56, 56, 128)       1152      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_3_bn (BatchNormali  (None, 56, 56, 128)       512       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_3_relu (ReLU)       (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv_pw_3 (Conv2D)          (None, 56, 56, 128)       16384     \n",
      "                                                                 \n",
      " conv_pw_3_bn (BatchNormali  (None, 56, 56, 128)       512       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_3_relu (ReLU)       (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv_pad_4 (ZeroPadding2D)  (None, 57, 57, 128)       0         \n",
      "                                                                 \n",
      " conv_dw_4 (DepthwiseConv2D  (None, 28, 28, 128)       1152      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_4_bn (BatchNormali  (None, 28, 28, 128)       512       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_4_relu (ReLU)       (None, 28, 28, 128)       0         \n",
      "                                                                 \n",
      " conv_pw_4 (Conv2D)          (None, 28, 28, 256)       32768     \n",
      "                                                                 \n",
      " conv_pw_4_bn (BatchNormali  (None, 28, 28, 256)       1024      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_4_relu (ReLU)       (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv_dw_5 (DepthwiseConv2D  (None, 28, 28, 256)       2304      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_5_bn (BatchNormali  (None, 28, 28, 256)       1024      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_5_relu (ReLU)       (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv_pw_5 (Conv2D)          (None, 28, 28, 256)       65536     \n",
      "                                                                 \n",
      " conv_pw_5_bn (BatchNormali  (None, 28, 28, 256)       1024      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_5_relu (ReLU)       (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv_pad_6 (ZeroPadding2D)  (None, 29, 29, 256)       0         \n",
      "                                                                 \n",
      " conv_dw_6 (DepthwiseConv2D  (None, 14, 14, 256)       2304      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_6_bn (BatchNormali  (None, 14, 14, 256)       1024      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_6_relu (ReLU)       (None, 14, 14, 256)       0         \n",
      "                                                                 \n",
      " conv_pw_6 (Conv2D)          (None, 14, 14, 512)       131072    \n",
      "                                                                 \n",
      " conv_pw_6_bn (BatchNormali  (None, 14, 14, 512)       2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_6_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_7 (DepthwiseConv2D  (None, 14, 14, 512)       4608      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_7_bn (BatchNormali  (None, 14, 14, 512)       2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_7_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_7 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_7_bn (BatchNormali  (None, 14, 14, 512)       2048      \n",
      " zation)                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " conv_pw_7_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_8 (DepthwiseConv2D  (None, 14, 14, 512)       4608      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_8_bn (BatchNormali  (None, 14, 14, 512)       2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_8_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_8 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_8_bn (BatchNormali  (None, 14, 14, 512)       2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_8_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_9 (DepthwiseConv2D  (None, 14, 14, 512)       4608      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_9_bn (BatchNormali  (None, 14, 14, 512)       2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_9_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_9 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_9_bn (BatchNormali  (None, 14, 14, 512)       2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_9_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_10 (DepthwiseConv2  (None, 14, 14, 512)       4608      \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv_dw_10_bn (BatchNormal  (None, 14, 14, 512)       2048      \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " conv_dw_10_relu (ReLU)      (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_10 (Conv2D)         (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_10_bn (BatchNormal  (None, 14, 14, 512)       2048      \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " conv_pw_10_relu (ReLU)      (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_11 (DepthwiseConv2  (None, 14, 14, 512)       4608      \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv_dw_11_bn (BatchNormal  (None, 14, 14, 512)       2048      \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " conv_dw_11_relu (ReLU)      (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_11 (Conv2D)         (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_11_bn (BatchNormal  (None, 14, 14, 512)       2048      \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " conv_pw_11_relu (ReLU)      (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pad_12 (ZeroPadding2D  (None, 15, 15, 512)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_12 (DepthwiseConv2  (None, 7, 7, 512)         4608      \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv_dw_12_bn (BatchNormal  (None, 7, 7, 512)         2048      \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " conv_dw_12_relu (ReLU)      (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " conv_pw_12 (Conv2D)         (None, 7, 7, 1024)        524288    \n",
      "                                                                 \n",
      " conv_pw_12_bn (BatchNormal  (None, 7, 7, 1024)        4096      \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " conv_pw_12_relu (ReLU)      (None, 7, 7, 1024)        0         \n",
      "                                                                 \n",
      " conv_dw_13 (DepthwiseConv2  (None, 7, 7, 1024)        9216      \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv_dw_13_bn (BatchNormal  (None, 7, 7, 1024)        4096      \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " conv_dw_13_relu (ReLU)      (None, 7, 7, 1024)        0         \n",
      "                                                                 \n",
      " conv_pw_13 (Conv2D)         (None, 7, 7, 1024)        1048576   \n",
      "                                                                 \n",
      " conv_pw_13_bn (BatchNormal  (None, 7, 7, 1024)        4096      \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " conv_pw_13_relu (ReLU)      (None, 7, 7, 1024)        0         \n",
      "                                                                 \n",
      " global_average_pooling2d_1  (None, 1024)              0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 1, 1, 1024)        0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1, 1, 1024)        0         \n",
      "                                                                 \n",
      " conv_preds (Conv2D)         (None, 1, 1, 1000)        1025000   \n",
      "                                                                 \n",
      " reshape_2 (Reshape)         (None, 1000)              0         \n",
      "                                                                 \n",
      " act_softmax (Activation)    (None, 1000)              0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4253864 (16.23 MB)\n",
      "Trainable params: 4231976 (16.14 MB)\n",
      "Non-trainable params: 21888 (85.50 KB)\n",
      "_________________________________________________________________\n",
      "/home/ehsan/Partial_Q//Imagenet/ILSVRC2012_img_val\n",
      "50000\n",
      "(224, 224, 3)\n",
      "(224, 224, 3)\n",
      "(224, 224, 3)\n",
      "(224, 224, 3)\n",
      "(224, 224, 3)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "***************************************************\n",
      "calibrate...\n",
      "\n",
      "calibrate: loading existing file /home/ehsan/Partial_Q//Keras/Quantization/Res/MobileNet_calibrated.tflite\n",
      "Do you want to reset df0.csv? yes/*   yes\n",
      "Total layers:37  Convs:34  number of cases:68\n",
      "case:\n",
      "1.0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m initialize()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(RESULTS_FILE):\n\u001b[0;32m---> 11\u001b[0m     \u001b[43mrun_0\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m#run()\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m#run_2()\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m#run_3()\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     run_MontCarlo(_Num_points\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6000\u001b[39m)\n",
      "Cell \u001b[0;32mIn[16], line 62\u001b[0m, in \u001b[0;36mrun_0\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m generate_indexes_0():\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m*****************\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCase:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mc[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mc[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[16], line 24\u001b[0m, in \u001b[0;36mgenerate_indexes_0\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m suspend\u001b[38;5;241m=\u001b[39mall_layers[:]\n\u001b[1;32m     23\u001b[0m quant\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m case:           \n\u001b[1;32m     25\u001b[0m     start_index\u001b[38;5;241m=\u001b[39mall_layers\u001b[38;5;241m.\u001b[39mindex(conv_layers[layer])\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m layer\u001b[38;5;241m==\u001b[39mlast_conv_indx:\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not iterable"
     ]
    }
   ],
   "source": [
    "                \n",
    "\n",
    "# # # +\n",
    "# # # # +\n",
    "#evaluate([])\n",
    "### run is for consequtive layer quantizations \n",
    "### and run_2 is for select two layer quantization\n",
    "## and run_3 for three layers\n",
    "## and for Montecarlo\n",
    "if __name__ == \"__main__\":\n",
    "    initialize()\n",
    "    if os.path.isfile(RESULTS_FILE):\n",
    "        run_0()\n",
    "        #run()\n",
    "        #run_2()\n",
    "        #run_3()\n",
    "        run_MontCarlo(_Num_points=6000)\n",
    "    else:\n",
    "        quantized_model=quantize(model,dataset)\n",
    "        debugger=explore(model,dataset)\n",
    "        run_debugger(debugger,RESULTS_FILE)\n",
    "        #run_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "endofcell": "--------",
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# # # + endofcell=\"-----\"\n",
    "# # # # # +\n",
    "\n",
    "# # # # + endofcell=\"----\"\n",
    "# # # # # # +\n",
    "def _run2():\n",
    "    ouput=os.getcwd()+\"/cases/\"\n",
    "    os.makedirs(output, exist_ok=True)\n",
    "    \n",
    "    \n",
    "    layer_stats = pd.read_csv(RESULTS_FILE)\n",
    "    all_layers=list(layer_stats[:]['tensor_name'])\n",
    "    conv_layers=[]\n",
    "    for i,layer in enumerate(all_layers):\n",
    "        if 'conv' in layer or 'StatefulPartitionedCall' in layer:\n",
    "            conv_layers.append(layer)\n",
    "            \n",
    "    _n=len(conv_layers)\n",
    "    #cases=[ [ conv_layers[start:end+1] for end in range(start,_n) ] for start in range(0,_n) ]\n",
    "    cases=[  list(range(start,end+1))  for start in range(0,_n) for end in range(start,_n)]\n",
    "    n_cases = [len(case) for case in cases ]\n",
    "    N_cases = sum(n_cases)\n",
    "    print(f'Total layers:{len(all_layers)}  Convs:{len(conv_layers)}  number of cases:{N_cases}')\n",
    "    \n",
    "    def data_case(i):\n",
    "        Data={}\n",
    "        start_conv=cases[i][0]\n",
    "        end_conv=cases[i][-1]\n",
    "        start_index=all_layers.index(conv_layers[start_conv])\n",
    "        if end_conv==len(conv_layers)-1:\n",
    "            end_index=len(all_layers)-1\n",
    "        else:\n",
    "            end_index=all_layers.index(conv_layers[end_conv+1])\n",
    "        suspend=all_layers[0:start_index]+all_layers[end_index:]\n",
    "        _name=f'{start_conv}-{end_conv}'\n",
    "        \n",
    "        Data['start_conv']=start_conv\n",
    "        Data['end_conv']=end_conv\n",
    "        Data['suspend']=suspend\n",
    "        Data['_name']=_name\n",
    "        return Data\n",
    "        \n",
    "    Data1=data_case(0)\n",
    "    thread = threading.Thread(target=explore_combinations2,args=(calibrated_model,suspected_layers:=c[-1],name:=m_name))\n",
    "    thread.start()\n",
    "    for j in range(1,len(cases)):\n",
    "        \n",
    "        #kk=list(set(all_layers)-set(suspend))\n",
    "        print(\"\\n\\n\\n*****************\")\n",
    "        print(f'quantizing conv layers from {start_conv} to {end_conv}')\n",
    "        print(f'index {start_index} to {end_index}')\n",
    "        print(all_layers[start_index:end_index])\n",
    "        print(f'Case:{i}/{N_cases}')\n",
    "        _name=f'{start_conv}-{end_conv}'\n",
    "        m_name=output+_name+'.tflite'\n",
    "        p_name=_name+'.pkl'\n",
    "        if i==0:\n",
    "            thread = threading.Thread(target=explore_combinations2,args=(calibrated_model,suspected_layers:=c[-1],name:=m_name))\n",
    "            thread.start()\n",
    "            thread.join()\n",
    "            \n",
    "        next_start_conv=cases[i+1][0]\n",
    "        next_end_conv=cases[i+1][-1]\n",
    "        next_start_index=all_layers.index(conv_layers[next_start_conv])\n",
    "        next_end_index=all_layers.index(conv_layers[next_end_conv+1])\n",
    "        next_suspend=all_layers[0:start_index]+all_layers[end_index:]\n",
    "        \n",
    "    for c in generate_indexes():\n",
    "        threads=[]\n",
    "        start_time=time.time()\n",
    "        print(\"\\n\\n\\n*****************\\n\\n\\n\")\n",
    "        print(f'Case:{c[0]}/{c[1]}')\n",
    "        _name=f'{c[2]}-{c[3]}'\n",
    "        m_name=output+_name+'.tflite'\n",
    "        p_name=_name+'.pkl'\n",
    "        thread = threading.Thread(target=explore_combinations2,args=(calibrated_model,suspected_layers:=c[-1],name:=m_name))\n",
    "        end_time=time.time()\n",
    "        print(f\"{mname} Quantization finished time: {end_time-start_time}\")\n",
    "        ## Trigger Evaluation\n",
    "        thread = threading.Thread(target=evaluate, args=[model_name:=m_name,pkl_name:=p_name])\n",
    "        threads.append(thread)\n",
    "\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "\n",
    "\n",
    "\n",
    "def generate_cases_keras():\n",
    "    all_layers=[l.name for l in model.layers]\n",
    "    conv_layers=[name for (indx,name) in enumerate(all_layers) if 'conv' in name]\n",
    "    _n=len(conv_layers)\n",
    "    cases=[ [ conv_layers[start:end+1] for end in range(start,_n) ] for start in range(0,_n) ]\n",
    "    n_cases = [len(case) for case in cases ]\n",
    "    N_cases = sum(n_cases)\n",
    "    flatted_cases=[c for case in cases for c in case]\n",
    "    #test=flatted_cases[4]\n",
    "    #t=explore_combinations2(calibrated_model,suspected_layers=test,name='ttt.tflite')\n",
    "    return flatted_cases\n",
    "\n",
    "def run_keras():\n",
    "    global calibrated_model\n",
    "    threads=[]\n",
    "    for case in flatted_cases:\n",
    "        start_time=time.time()\n",
    "        c=f'{case[0]}-{case[-1]}'\n",
    "        mname=resdir+c+'.tflite'\n",
    "        print(f\"Quantizaing layers {c} --> {mname}\")\n",
    "        explore_combinations2(calibrated_model,suspected_layers=case,name=mname)\n",
    "        end_time=time.time()\n",
    "        print(f\"{mname} Quantization finished time: {end_time-start_time}\")\n",
    "        thread = threading.Thread(target=evaluate, args=[model_name:=mname,pkl_name:=f'{c}.pkl'])\n",
    "        threads.append(thread)\n",
    "        input(\"one_run...\")\n",
    "\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "\n",
    "\n",
    "# # # # # + endofcell=\"--\"\n",
    "# -\n",
    "\n",
    "'''\n",
    "sq=selective_quantize(model,dataset,t=0.31,p=0.3)\n",
    "calibrated_model=calibrate(model,dataset)\n",
    "quantized_model=quantize(model,dataset)\n",
    "debugger=explore(model,dataset)\n",
    "run_debugger(debugger,RESULTS_FILE)\n",
    "Analyze(RESULTS_FILE_ANALYZED)\n",
    "selective_quantized=selective_quantize(model,dataset)\n",
    "calibrated_model=calibrate(model,dataset)\n",
    "debugger=explore_propogation(calibrated_model,dataset)\n",
    "run_debugger(debugger,RESULTS_FILE_Propogate)\n",
    "Analyze(RESULTS_FILE_Propogate_ANALYZED)\n",
    "calibrated_model=calibrate(model,dataset)\n",
    "selective_unquantized=explore_combinations(calibrated_model)'''\n",
    "\n",
    "\n",
    "# # # # # # # # # %%timeit -n 1 -r 1\n",
    "def ttt():\n",
    "    QuantizedName='Yolo_files/1/YoloV3_quztized.tflite'\n",
    "    model = interpreter_wrapper.Interpreter(model_path=QuantizedName)\n",
    "    model.allocate_tensors()\n",
    "    model_format = 'TFLITE'\n",
    "    model_input_shape=(608,608)\n",
    "    #Ehsan input shape correctness\n",
    "    input_details = model.get_input_details()\n",
    "    output_details = model.get_output_details()\n",
    "    input_shape = input_details[0]['shape']\n",
    "\n",
    "    n=100\n",
    "    input_shape[0]=n\n",
    "    input_shape[1] = model_input_shape[0]\n",
    "    input_shape[2] = model_input_shape[1]\n",
    "    model.resize_tensor_input(0, input_shape)\n",
    "    model.allocate_tensors()\n",
    "    print(input_shape)\n",
    "    input_shape=[n,608,608,3]\n",
    "    input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
    "    # Set the input tensor to the interpreter\n",
    "    model.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "    # Run the model on the GPU\n",
    "    with tf.device('/gpu:1'):\n",
    "        model.invoke()\n",
    "\n",
    "    # Get the output tensor from the interpreter\n",
    "    output_data = model.get_tensor(output_details[0]['index'])\n",
    "\n",
    "    output_data\n",
    "# ---\n",
    "# --\n",
    "# ----\n",
    "# -----\n",
    "# ------\n",
    "# -------\n",
    "\n",
    "\n",
    "a=list(range(10))\n",
    "import itertools\n",
    "cases=list(itertools.combinations(a, 1))\n",
    "cases+=list(itertools.combinations(a, 2))\n",
    "cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Q_Partial",
   "language": "python",
   "name": "q_partial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
