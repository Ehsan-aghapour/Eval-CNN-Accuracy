{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbb1eea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./env_keras/lib/python3.10/site-packages (1.26.1)\n",
      "Requirement already satisfied: tensorflow in ./env_keras/lib/python3.10/site-packages (2.14.0)\n",
      "Requirement already satisfied: keras in ./env_keras/lib/python3.10/site-packages (2.14.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./env_keras/lib/python3.10/site-packages (from tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./env_keras/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in ./env_keras/lib/python3.10/site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./env_keras/lib/python3.10/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./env_keras/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in ./env_keras/lib/python3.10/site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./env_keras/lib/python3.10/site-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in ./env_keras/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.23.5 in ./env_keras/lib/python3.10/site-packages (from tensorflow) (1.26.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./env_keras/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in ./env_keras/lib/python3.10/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in ./env_keras/lib/python3.10/site-packages (from tensorflow) (4.25.0)\n",
      "Requirement already satisfied: setuptools in ./env_keras/lib/python3.10/site-packages (from tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./env_keras/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./env_keras/lib/python3.10/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./env_keras/lib/python3.10/site-packages (from tensorflow) (4.8.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in ./env_keras/lib/python3.10/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./env_keras/lib/python3.10/site-packages (from tensorflow) (0.34.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./env_keras/lib/python3.10/site-packages (from tensorflow) (1.59.2)\n",
      "Requirement already satisfied: tensorboard<2.15,>=2.14 in ./env_keras/lib/python3.10/site-packages (from tensorflow) (2.14.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in ./env_keras/lib/python3.10/site-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./env_keras/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.41.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in ./env_keras/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.23.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in ./env_keras/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./env_keras/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.5.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./env_keras/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./env_keras/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./env_keras/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./env_keras/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./env_keras/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./env_keras/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./env_keras/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./env_keras/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./env_keras/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./env_keras/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./env_keras/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./env_keras/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in ./env_keras/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./env_keras/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install tensorflow keras\n",
    "!pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae5065df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ehsan/Partial_Q/Keras/env_keras/bin/python\n"
     ]
    }
   ],
   "source": [
    "#make sure that it is the right environment\n",
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0957b869",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-09 03:33:47.158921: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-09 03:33:47.198614: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-09 03:33:47.198669: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-09 03:33:47.198692: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-09 03:33:47.205378: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-09 03:33:47.206240: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-09 03:33:48.054513: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      " 1/32 [..............................] - ETA: 5:05WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff7944b0160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      " 1/32 [..............................] - ETA: 4:59WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff7944b0160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "32/32 [==============================] - 67s 2s/step\n",
      "32/32 [==============================] - 67s 2s/step\n",
      "32/32 [==============================] - 68s 2s/step\n",
      "32/32 [==============================] - 70s 2s/step\n",
      "32/32 [==============================] - 75s 2s/step\n",
      "32/32 [==============================] - 75s 2s/step\n",
      "32/32 [==============================] - 73s 2s/step\n",
      "32/32 [==============================] - 73s 2s/step\n",
      "32/32 [==============================] - 68s 2s/step\n",
      "32/32 [==============================] - 76s 2s/step\n",
      "32/32 [==============================] - 73s 2s/step\n",
      "32/32 [==============================] - 72s 2s/step\n",
      "32/32 [==============================] - 73s 2s/step\n",
      "32/32 [==============================] - 74s 2s/step\n",
      "32/32 [==============================] - 74s 2s/step\n",
      "32/32 [==============================] - 74s 2s/step\n",
      "32/32 [==============================] - 75s 2s/step\n",
      "32/32 [==============================] - 69s 2s/step\n",
      "32/32 [==============================] - 78s 2s/step\n",
      "32/32 [==============================] - 74s 2s/step\n",
      "32/32 [==============================] - 71s 2s/step\n",
      "32/32 [==============================] - 76s 2s/step\n",
      "32/32 [==============================] - 70s 2s/step\n",
      "32/32 [==============================] - 75s 2s/step\n",
      "32/32 [==============================] - 73s 2s/step\n",
      "32/32 [==============================] - 65s 2s/step\n",
      "32/32 [==============================] - 79s 2s/step\n",
      "32/32 [==============================] - 76s 2s/step\n",
      "32/32 [==============================] - 79s 2s/step\n",
      "32/32 [==============================] - 71s 2s/step\n",
      "32/32 [==============================] - 74s 2s/step\n",
      "32/32 [==============================] - 77s 2s/step\n",
      "32/32 [==============================] - 74s 2s/step\n",
      "32/32 [==============================] - 76s 2s/step\n",
      "32/32 [==============================] - 72s 2s/step\n",
      "32/32 [==============================] - 74s 2s/step\n",
      "32/32 [==============================] - 75s 2s/step\n",
      "32/32 [==============================] - 67s 2s/step\n",
      "32/32 [==============================] - 79s 2s/step\n",
      "32/32 [==============================] - 67s 2s/step\n",
      "32/32 [==============================] - 67s 2s/step\n",
      "32/32 [==============================] - 67s 2s/step\n",
      "32/32 [==============================] - 73s 2s/step\n",
      "32/32 [==============================] - 68s 2s/step\n",
      "32/32 [==============================] - 28s 703ms/step\n",
      "32/32 [==============================] - 15s 453ms/step\n",
      "32/32 [==============================] - 15s 468ms/step\n",
      "32/32 [==============================] - 15s 449ms/step\n",
      "32/32 [==============================] - 15s 466ms/step\n",
      "32/32 [==============================] - 12s 369ms/step\n",
      "Total time of Evaluation: 167.03345894813538\n",
      "Overall top-1 accuracy: 68.3620%\n",
      "Overall top-5 accuracy: 88.2540%\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Constants\n",
    "model_name='MobileNet/MobileNet.h5'\n",
    "models_dir='/home/ehsan/Partial_Q/models/'\n",
    "Proj_DIR=\"/home/ehsan/Partial_Q/\"\n",
    "IMAGE_DIR = Proj_DIR+'/Imagenet/ILSVRC2012_img_val'\n",
    "LABEL_FILE = Proj_DIR+'/Evaluation/Ground_labels/ground_labels.txt'\n",
    "LABEL_MAP=Proj_DIR+'/Keras/labels.txt'\n",
    "BATCH_SIZE = 1000  # Adjust as needed\n",
    "N=50000\n",
    "NUM_CLASSES = 1000  # Number of ImageNet classes\n",
    "\n",
    "\n",
    "# Load model\n",
    "def _load_model(MODEL_NAME):\n",
    "    #model = load_model(models_dir+model_name)\n",
    "    global model\n",
    "    model = load_model(MODEL_NAME)\n",
    "\n",
    "\n",
    "\n",
    "# Step 1: Create a mapping from class names to indices based on labels.txt\n",
    "label_index_map = {}\n",
    "with open(LABEL_MAP, 'r') as f:\n",
    "    for index, line in enumerate(f):\n",
    "        class_name = line.strip().split(' ')[0]\n",
    "        label_index_map[class_name] = index\n",
    "\n",
    "# Step 2: Read ground_labels.txt and convert the labels to indices\n",
    "ground_truth_indices = []\n",
    "with open(LABEL_FILE, 'r') as f:\n",
    "    for line in f:\n",
    "        class_name = line.strip().split(' ')[0]\n",
    "        if class_name in label_index_map:\n",
    "            ground_truth_indices.append(label_index_map[class_name])\n",
    "        else:\n",
    "            print(f\"Label {class_name} not found in label index map.\")\n",
    "            ground_truth_indices.append(None)  # Handle missing labels if necessary\n",
    "\n",
    "# Now, ground_truth_indices contains the true indices for each image\n",
    "# Preprocessing function\n",
    "def preprocess_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "def run_predict(batch_images):\n",
    "    batch_preds = model.predict(batch_images)\n",
    "    return batch_preds\n",
    "\n",
    "# Evaluation function to be used in each process\n",
    "def evaluate_batch(batch_images, batch_labels):\n",
    "    batch_preds = run_predict(batch_images)\n",
    "    top1_correct = np.sum(np.argmax(batch_preds, axis=1) == batch_labels)\n",
    "    top5_correct = np.sum([label in pred for label, pred in zip(batch_labels, np.argsort(batch_preds, axis=1)[:, -5:])])\n",
    "    return top1_correct, top5_correct\n",
    "\n",
    "\n",
    "# Thread worker function\n",
    "def thread_worker(image_paths, labels):\n",
    "    #print(f'running for images {len(image_paths)}')\n",
    "    batch_images = np.vstack([preprocess_image(img_path) for img_path in image_paths])\n",
    "    top1 , top5 = evaluate_batch(batch_images, labels)\n",
    "    return [top1, top5]\n",
    "\n",
    "\n",
    "\n",
    "def main(Model_Name=models_dir+model_name):\n",
    "    _load_model(Model_Name)\n",
    "    # Gather image paths and labels\n",
    "    image_paths = [os.path.join(IMAGE_DIR, fname) for fname in sorted(os.listdir(IMAGE_DIR))][:N]\n",
    "\n",
    "    #labels = to_categorical(true_labels, NUM_CLASSES)\n",
    "    labels=ground_truth_indices\n",
    "\n",
    "    # Split into batches\n",
    "    batches = [(image_paths[i:i + BATCH_SIZE], labels[i:i + BATCH_SIZE]) for i in range(0, len(image_paths), BATCH_SIZE)]\n",
    "\n",
    "\n",
    "    time1=time.time()\n",
    "    # Perform multi-threaded evaluation\n",
    "    top1_correct = top5_correct = total_images = 0\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=128) as executor:\n",
    "        # Submit all the tasks and get back Future objects\n",
    "        futures = [executor.submit(thread_worker, batch[0], batch[1]) for batch in batches]\n",
    "\n",
    "        # Iterate over the completed futures as they complete\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            top1, top5 = future.result()  # Unpack the result from the future\n",
    "            top1_correct += top1\n",
    "            top5_correct += top5\n",
    "            total_images += BATCH_SIZE  # Make sure to update the total_images if not all images are used\n",
    "\n",
    "    time2=time.time()\n",
    "    t=time2-time1\n",
    "    print(f\"Total time of Evaluation: {t}\")\n",
    "    # Calculate overall accuracies\n",
    "    overall_top1_accuracy = top1_correct / total_images  # This should be total_images, not N, in case N is not a multiple of BATCH_SIZE\n",
    "    overall_top5_accuracy = top5_correct / total_images\n",
    "    print(f\"Overall top-1 accuracy: {overall_top1_accuracy * 100:.4f}%\")\n",
    "    print(f\"Overall top-5 accuracy: {overall_top5_accuracy * 100:.4f}%\")\n",
    "     \n",
    "\n",
    "#main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770d007b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Q_Partial",
   "language": "python",
   "name": "q_partial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
